#!/usr/bin/perl -w

# $Id$

#use strict;

package nimblewiki;

# %q = ();

$| = 1;		# flush after each print

$wikiword = "[A-Z][a-z0-9]+";
$wikilink = "(?:$wikiword){2,}";
$interprefix = "[A-Z][A-Za-z0-9]+";
$interword = "[A-Za-z0-9]+";
$interquery = "$interword(?:[_+#?:.-]$interword)*";
#$markurl = "\001";

### Read in configuration variables ###
do "config.pl";

sub unescape_uri {
    $_ = shift;
    return undef unless defined;
    tr/+/ /;
    s/%([0-9a-fA-F]{2})/pack("C",hex($1))/ge;
    return $_;
}

sub escape_uri {
    my ($uri) = @_;

    # escape a minimal set - probably more chars are needed here
#    $uri =~ s/([&=+?])/"%" . unpack("H2", $1)/ge;
    $uri =~ s/([&=+?\000-\037\177])/"%" . unpack("H2", $1)/ge;
    $uri =~ tr/ /+/;	# may have to be %20
    $uri;
}

sub escape_html {
    s/&/&amp;/g;
    s/&amp;([a-zA-Z]+);/&$1;/g;   # unescape character entities
    s/</&lt;/g;
    s/>/&gt;/g;
}

sub parse_http_data {
    my @pairs;
    foreach (split( /&/, shift)) {
	my ($key, $value) = split(/=/, $_, 2);
	push @pairs, unescape_uri($key), unescape_uri($value);
    }
    @pairs;
}

sub choke {
    my ($errortext) = @_;
    my $subject = escape_uri($errortext);
    print <<EOT;
Content-type: text/html

<html>
  <head>
    <title>$wikiname :: An error occurred</title>
  </head>
  <body>
    <h1>Something went terribly wrong</h1>
    <p>An error occurred processing your last request.</p>
    <p>The error message was <em>$errortext</em>.</p>
    <p>Please <a href="mailto:$webhamster?subject=$subject">contact</a> the
       ding-dong responsible for this site with details about what you
       were doing when this happened.</p>
    <p>Thank you.</p>
  </body>
</html>
EOT
    exit;
}

sub read_file {
    my ($filename) = @_;
    my $contents = "";

    open F, "< $filename" or choke "open $filename (for reading) failed: $!";
    local $/;  # slurp mode
    $contents = <F>;
    close F;
#    print STDERR "reading file $filename = $contents\n";
    $contents;
}

sub write_file {
    my ($filename, $contents) = @_;

#    print STDERR "writing file $filename = $contents\n";
    open F, "> $filename" or choke "open $filename (for writing) failed: $!";
    print F $contents;
    close F;
}

sub append_file {
    my ($filename, $contents) = @_;

    open F, ">> $filename" or choke "open $filename (for appending) failed: $!";
    print F $contents;
    close F;
}

sub init_interwiki {
    my $file = "intermap";
    %intermap = (-r "$file" && -f "$file") ? split /\s+/, read_file($file) : ();
}

sub do_init {
    $script = (split '/', $ENV{'SCRIPT_NAME'})[-1];	# keep only last part

    $editable = $script eq $editscript;

    %dispatch = ( show   => \&do_show,
		  edit   => $editable ? \&do_edit : \&do_show,
		  search => \&do_text_search,
		  name   => \&do_name_search,
		  diff   => \&do_diff
		  );

    $method = $ENV{'REQUEST_METHOD'};
    if ($method =~ m/post/i){ 
	read(STDIN, my $form, $ENV{'CONTENT_LENGTH'});
	%form = parse_http_data($form);
    }

    ($page, $action, %query) = parse_http_data($ENV{'QUERY_STRING'});
    ($page, $action) = ($action, $page) if $action;
    $action ||= "show";		# ?page -> ?show=page    
    $page ||= $defaultpage;	# empty -> ?DefaultPage

    $textsearchform = <<"";
<form action="$script" method="get" enctype="application/x-www-form-urlencoded">
  <p><input type="text" name="search" size="30" /></p>
</form>

    $namesearchform = <<"";
<form action="$script" method="get" enctype="application/x-www-form-urlencoded">
  <p><input type="text" name="name" size="30" /></p>
</form>

    init_interwiki();
    $content = "";
    $footer = "";
}

sub scriptlink {
    my ($link, $linktext) = @_;
    "<a href=\"$script?$link\">$linktext</a>";
}

sub scriptlinkclass {
    my ($link, $linktext, $class) = @_;
    "<a class=\"$class\" href=\"$script?$link\">$linktext</a>";
}

sub do_request {
    do_init();
#    print_debug_values();

    # $action will match show" ...
    $method =~ m/post/i
	# both Save & Tweak buttons save the edit
	&& $form{'submit'} =~ m/(save|tweak)/i
	&& do_save() != 0
	&& return;

    # dispatch unless we saved and save failed
    &{$dispatch{$action}}();		# ... does this as well on save
}

sub fancy_title {
    my ($title) = @_;

    if ($title =~ m/$wikilink/) {
	$title =~ s/([a-z])([A-Z0-9])/$1 $2/g;
    }
    else {
	$title =~ tr/_/ /;
	$title =~ s/^([a-z])/uc($1)/e;	# capitalize first letter
    }
    $title
}

sub fancy_link {
    my ($link) = @_;

    $link =~ tr/_/ /;	# works for both wiki and extended links
    $link;
}

sub generate_xhtml {
    my ($title, $heading, $robots) = @_;
    my $home_link = scriptlink("$defaultpage",
	  "<img id=\"icon\" src=\"$iconimgsrc\" alt=\"$iconimgalt\" />");

    # Mostly we want the title and heading to be the same text. $heading is
    # usually a link to a search page, but the link text is the same as
    # $title. To get this behavior, pass "" for $heading. Sometimes,
    # though, they need to be different: if, for instance, we want inline
    # markup in the heading but not in the title (where it violates the
    # html spec). Or if we _don't_ want $heading to be a link (like on edit
    # pages).
    #
    # There is another wrinkle to this. We don't want web spiders to follow
    # links to edit or search pages and follow the links because they might
    # get stuck in circles or do damage to the wiki. Only "normal"
    # (do_show) pages should be indexed.

    my $meta_robots = "${robots}index,${robots}follow" ;
    $heading = scriptlink("search=$page", "$title") unless $heading;
    $heading_template =~ s/<home \/>/$home_link/;
    $heading_template =~ s/<heading \/>/$heading/;

    print <<EOT;
Content-type: text/html

<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html 
          PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta name="keywords" content="$keywords" />
<meta name="description" content="$description" />
<meta name="copyright" content="$copyright" />
<meta name="robots" content="$meta_robots" />
<link rel="stylesheet" href="$style" type="text/css" />
<title>$wikiname :: $title</title>
</head>
<body>

<div id="header">
$heading_template
</div>

<div id="content">
$content
</div>

<div id="footer">
$footer
</div>

</body>
</html>
EOT
}

# This bit of code is ugly because it is being passed an array of references
# to scalars that are to be modified. Hence the $$n everywhere.
sub leading_zero {
    my @nums = @_;
    foreach my $n (@nums) {
	$$n = "0$$n" if ($$n < 10);
    }
}

sub pretty_time {
    my ($time) = @_;
    my ($sec, $min, $hour, $mday, $mon, $year, $wday, $yday) = localtime($time);
    $year += 1900;
    my $month = (qw(January February March April May June July
		    August September October November December))[$mon];
    $mon = $mon + 1;	# was indexed from 0
    leading_zero \($mon, $mday, $hour, $min, $sec);
    ($year, $mon, $month, $mday, $hour, $min, $sec);
}

sub stamp {
    my ($time) = @_;
    my ($year, $mon, $month, $mday, $hour, $min, $sec) = pretty_time($time);
    "$year $month $mday $hour:$min";
}

sub iso_timestamp {
    my ($time) = @_;
    my ($year, $mon, $month, $mday, $hour, $min, $sec) = pretty_time($time);
    "$year-$mon-$mday" . "T" . "$hour:$min:$sec";
}

# If the file doesn't exist or isn't readable, use a modtime of 0.
# We're long past 1970, so this should be ok. ;-)
sub modtime {
    my ($file) = @_;
    (-r "$file" && -f "$file") ? (stat "$file")[9] : 0;
}

sub modtimestring {
    my ($file) = @_;
    stamp(modtime("$file"));
}

sub editfooter {
    my $edittext = scriptlink("edit=$page", "EditText") . " of this page";

# waiting for diff links until we have some kind of diffing!
#    my $modtext  = " (last edited " . scriptlink("diff=$page", $mod) . ")" if $page && $mod;

    my $modtime = modtime("$pagedir/$page");
    my $modtext  = ($modtime != 0)
	? " (last edited " . stamp($modtime) . ")"
	: "";

    $footer .= "$edittext$modtext<br />\n";
}

sub findfooter {
    $footer .= scriptlink("SearchWiki", "SearchWiki")
	. " for titles or text,\n"
	. "browse " . scriptlink("RecentChanges", "RecentChanges") . ",\n"
	. "or return to " . scriptlink($defaultpage, $defaultpage) . "\n";
#Search for &nbsp;$searchform
#Pages like &nbsp;$namesearchform

}

sub validator {
    $footer .= << "";
<p>
<a href="http://validator.w3.org/check/referer">
  <img src="images/valid-xhtml10" alt="Valid XHTML 1.0 Strict!" />
</a>
<a href="http://jigsaw.w3.org/css-validator/">
  <img src="images/valid-css" alt="Valid CSS!" />
</a>
</p>

}

sub make_wiki_link {
    my ($page) = @_;
    my $link = fancy_link($page);
    (-r "$pagedir/$page" && -f "$pagedir/$page")
	? scriptlink($page, $link)
#        : "$page" . ($editable ? scriptlink("edit=$page", "[?]") : "");
        : ($editable ? scriptlinkclass("$page", $link, "missing")
	   : "$page");
}

# a way to escape query strings? Thinking of google queries w/embedded spaces.
sub make_interwiki_link {
    my ($prefix, $suffix, $link_text) = @_;
    my $interlink = $intermap{$prefix};

    $link_text =~ tr/_/ /;
#    $link_text =~ s/#/ :: /g;

    defined $interlink
	? "<a href=\"$interlink$suffix\">$link_text</a>" : "$link_text";
}

sub hide {
    my ($link) = @_;

    # use "" to hide links
    $link =~ s/($wikiword)/$1\"\"/go;
#   $link =~ s/($extendedlinkbit)/$1\"\"/go;
    $link;
}

sub convert_wiki_links {
    s/($wikilink)/make_wiki_link($1)/geo;
#    s/($extendedlinkre)/make_wiki_link($1)/geo;

    # forced link of single word
#    s/``($extendedlinkbit)/make_wiki_link($1)/geo;
}

sub convert_interwiki_links {
    s/($interprefix):($interquery)/hide(make_interwiki_link($1, $2, "$1:$2"))/geo;
}

@nestelems = ();
$nestdepth = 0;

sub pushelem {
    my ($type) = @_;
    my $out = indent() . "<$type>";
    push @nestelems, $type;
    $nestdepth++;
    $out;
}

sub popelem {
    $nestdepth--;
    indent() . "</" . (pop @nestelems) . ">\n";
}

sub unwind {
    my $out = "";
    $out .= popelem() while ($nestdepth);
    $out;
}

sub indent {
    ' ' x ($nestdepth * 2);
}

# I just learned that nested ol and ul elements have to be _inside_ an li.
# ol and ul can only contain li - nothing else. So we need to rewrite this
# code to keep li's "open" until the last possible moment. Make them part of
# of the pushelem/popelem code. Misuse of nesting (by wiki content authors)
# may result in li's with no text content.

# a couple of thoughts. use split //, type to blow up type/nesting into an
# array/list of chars. Iterate over this to do indenting.

sub listitem {
    my ($type, $text) = @_;
    my $out = "";
    my $elem = $type =~ m/\*/ ? "ul" : "ol";
    my $depth = 2 * (length $type) - 1;
    
    if ($nestdepth == 0)
    { $out .= pushelem($elem) . "\n"; }
    else
	# close last open li
    { $out .= popelem(); }

    $out .= pushelem("li") . "\n" . pushelem($elem) . "\n"
	while ($depth > $nestdepth);

    $out .= popelem()
	while ($depth < $nestdepth);

    # now we're at the right level but might be inside a different list elem
    $out .= popelem() . pushelem("li") . "\n" . pushelem($elem) . "\n"
	if ($nestelems[-1] ne $elem);

    # now indent and add open li and text
    $out . pushelem("li") . $text . "\n";


    $out .= pushelem($elem) . "\n" . pushelem("li") while ($depth > $nestdepth);
    $out .= popelem()                               while ($depth < $nestdepth);

    # now we're at the right level but might be inside a different nest elem
    $out .= popelem() . pushelem("li") . pushelem($elem)
	if (@nestelems && $nestelems[-1] ne $elem);

    # now indent for item
    $out . indent() . "<li>$text</li>";
}

sub listblock {
    my ($listpara) = @_;
    my $elem = $listpara =~ m/\*/ ? "ul" : "ol";

    $listpara =~ s:^([*#]{1,5})\s*(.*):<li>$2</li>\n:gm;

    wrap("$elem", "\n$listpara");
}

sub wrap {
    my ($elem, $contents) = @_;
    "<$elem>$contents</$elem>";
}

sub block_markup {
    s#^(\s+.*)#<pre>\n$1\n</pre>#s ||
    s#^"(.*)#<blockquote>$1</blockquote>#s ||
    s#^;(.*)#<blockquote>$1</blockquote>#s ||

    s#^-{4,}#<hr /># ||
    s/^(={1,4})\s*(.*)/wrap("h".((length $1)+1), $2)/e ||
#    s/^([*#]{1,5})\s*(.*?)/listitem($1, $2)/gme ||
#    s/^([*#]{1,5}.*?)/listblock($1)/e ||

    # special links - these generate form elements, which are considered to
    # be block-level markup. In order to validate, these cannot be enclosed
    # in p elems.
    s/^\[namesearch\]/$namesearchform/ ||
    s/^\[textsearch\]/$textsearchform/ ||

    # nothing else matches, make it a p
    s#^(.*)#<p>$1</p>#s;

}

sub hideuri {
    $uri[$uri++] = shift;
    "$urimark$uri$urimark";
}

sub hide_uris {
#    s/\[\[.+\]\]/hideuri($1)/ge;
}

sub show_uris {
    # remove double quotes - can be used to foil wikilinks, and to
    # add plurals to singularly-linked pages
    s/""//g;
}

sub inline_markup {
    hide_uris();

    # this one should be first: it wreaks havoc with slashes!!
    s#'{3}(.+?)'{3}#<strong>$1</strong>#gs;
    s#'{2}(.+?)'{2}#<em>$1</em>#gs;
    # XXX: code, cite, kbd, ???

    # named interwiki link: [[prefix:suffix link text]]
    s/\[\[($interprefix):($interquery)\s+(.+?)\]\]/hide(make_interwiki_link($1, $2, $3))/geo;

    # inline img link: [[uri.ext alt text]] where ext is img type
    s#\[\[(\S+\.(?:jpg|jpeg|gif|png))\s+(.+?)\]\]#hide(
	"<img src=\"$1\" alt=\"$2\" />")#ge;

    # unnamed href link: [[uri]]
    s#\[\[(\S+?)\]\]#hide("<a href=\"$1\">$1</a>")#ge;

    # generic href link: [[url lots of link text]]
    s#\[\[(\S+?)\s+(.+?)\]\]#hide("<a href=\"$1\">$2</a>")#ge;

    # ISBN ...
    # RFC ...

    convert_interwiki_links();
    convert_wiki_links();

    show_uris();
}

sub page_text {
    my ($page) = @_;
    my $file  = "$pagedir/$page";
    (-r "$file" && -f "$file") ? read_file($file) : "";
}

sub render_body {
    escape_html();

    # XXX if we do inline on a per-para basis, we can "catch" dangling
    # markup that spans para boundaries. I wonder if everything shouldn't
    # be wrapped in the foreach by para.
#    inline_markup();

    # we're going to do "paragraph" markup delimited with multiple newlines
    foreach (split /\n{2,}/, $_) {
	inline_markup() unless m/^\s+/;  # leave pre alone
	block_markup();
	$content .= "$_\n" , unwind();
    }
    $content .= "<hr />";
}

# do_xxx needs to do something like this:
# $content = ...
# $footer  = ...
# generate_xhtml($title, $page_heading);
sub do_show {
    my $robots = "";
    $_ = page_text($page);

    unless ($_) {
	$_ = "$page doesn't exist. Why not create it by editing the text of this page?\n";
	$robots = "no";
    }

    render_body();
    editfooter() if $editable;
    findfooter();
    validator();
    generate_xhtml(fancy_title($page), "", $robots);
}

sub make_edit_page {
    my ($text) = @_;
    my $mod = modtime("$pagedir/$page");

    $content .= <<"";
<form action="$script?$page" method="post" enctype="application/x-www-form-urlencoded">
  <p>
    <textarea name="edittext" rows="25" cols="75">$text</textarea>
  </p>
  <p>
    Comment about changes you made:<br />
    <input type="text" name="comment" value="Ignore this for now" size="75" />
  </p>
  <p>
    If you've made only small changes - like to punctuation or spelling -
    and don't want a new entry in RecentChanges - press Tweak.
    Otherwise, to save changes and log RecentChanges, press Save.
  </p>
  <p>
    <input type="submit" name="submit" value="Save" />
    <input type="submit" name="submit" value="Tweak" />
    <input type="reset"                value="Revert" />
    <input type="submit" name="submit" value="Cancel" />
    <input type="hidden" name="modtime" value="$mod" />
  </p>
</form>

    validator();
    my $edit_title = "Editing " . fancy_title($page);

    # prevent making title a link, no robots
    generate_xhtml($edit_title, $edit_title, "no");
}

sub do_edit {
    make_edit_page(page_text($page));
}

sub make_backup_page {
    my ($page, $modstring) = @_;
    my $file = "$pagedir/$page";
    if (-r "$file" && -f "$file") {
	my $backup_file = "$archivedir/$page." . $modstring;
	write_file($backup_file, page_text($page));
    }
}

sub do_save {
    my $edit = $form{'edittext'};
    $edit =~ s/\r//g;	# CRLF -> LF

    my $mod_current = modtime("$pagedir/$page");

    # we have to check for edit collisions
    if ($mod_current != $form{'modtime'}) {
	$content = <<"";
<p>
Unfortunately, someone else has edited and saved $page since you started
editing it. The edit area still contains <strong>your</strong> version; if
you open an edit window on the current version of the page, you'll be able
to merge your changes.
</p>

        make_edit_page($edit);
	return -1;	# we failed to save, so don't do a "show"
    }
	
    make_backup_page("$page", iso_timestamp("$mod_current"));

    # convert time stamps - now honors <pre>
    my $stamp = stamp(time());

    # XXX: change this when splitting method changes in rendering code
    # we're going to do "paragraph" markup delimited with multiple newlines
    # leave pre alone
    # This bit of code has the added affect of canonicalizing the edited text:
    # chunks (paras) are separated by exactly two \n's, and the whole thing,
    # when written out to disk, is followed by a single \n.

    my @paras =  split /\n{2,}/, $edit;
    foreach my $para (@paras) {
	$para =~ s/\[now\]/$stamp/ge unless $para =~ m/^\s+/;
    }

    # joins bits together separated by \n\n, and add trailing \n
    write_file("$pagedir/$page", (join "\n\n", @paras) . "\n");

    my $ip = $ENV{'REMOTE_ADDR'};
# XXX: remove 2nd \n after I fix ul code!!
# XXX: and add back in the '* ' at the start of the line!!
#    my $text = "* $page (modified $stamp from $ip)\n\n";
    my $text = "$page ... $stamp ... $ip\n\n";

    # tweak will save edit but not affect RecentChanges
    if ($form{'submit'} =~ m/save/i) {
	# prefix existing contents of RecentChanges with newest entry.
	my $contents = $text . page_text("RecentChanges");
	write_file("$pagedir/RecentChanges", $contents);
    }
#    print "Content-type: text/plain\n\n$contents";
    return 0;
}

# XXX: if I knew Perl, and/or if Perl was a nicer language, I would pass
# a predicate function to a common routine.
sub do_text_search {
    opendir PAGES, "$pagedir" or choke "can't opendir $pagedir: $!";
    my @matches = grep { ! m/^\./ && -r "$pagedir/$_" && -f "$pagedir/$_" 
			 && (page_text($_) =~ m/$page/i) } readdir PAGES;
    closedir PAGES;
    gen_search_page("Pages matching $page",
		    "Pages matching <em>$page</em>", @matches);
}

sub do_name_search {
    opendir PAGES, "$pagedir" or die "can't opendir $pagedir: $!";
    my @matches = grep { ! m/^\./ && -r "$pagedir/$_" && -f "$pagedir/$_"
			 && m/$page/i } readdir PAGES;
    closedir PAGES;
    gen_search_page("Page names matching $page",
		    "Page names matching <em>$page</em>", @matches);
}

sub gen_search_page {
    my ($title, $heading, @matches) = @_;
    my $text = "";
    foreach (sort @matches) {
	$text .= "<li>" . make_wiki_link($_, $_) . "</li>\n";
    }
    $content  = "<ul>\n$text</ul>\n" if $text;
    $content .= "<hr />";
    findfooter();
    validator();
    generate_xhtml($title, $heading, "no");
}

sub do_diff {
}

sub do_choke {
    $_ = read_file("xyzzy");
}

sub print_debug_values {
    print STDERR "\n\n======================== new CGI call =========================\n";
    print STDERR ":: ENV ::\n";
    foreach (sort keys %ENV) {
	print STDERR "$_ = $ENV{$_}\n";
    }
    print STDERR "\n:: Query ::\n";
    foreach (sort keys %query) {
	print STDERR "$_ = $query{$_}\n";
    }
    print STDERR "\n:: Form ::\n";
    foreach (sort keys %form) {
	print STDERR "$_ = $form{$_}\n";
    }
    print STDERR "\n:: Intermap ::\n";
    foreach (sort keys %intermap) {
	print STDERR "$_ = $intermap{$_}\n";
    }
    print STDERR "\n:: VARIABLES ::\n";
    print STDERR "script = $script\n";
#    print STDERR "base = $base\n";
    print STDERR "page = $page\n";
    print STDERR "action = $action\n";
}

do_request();
#do_choke();
